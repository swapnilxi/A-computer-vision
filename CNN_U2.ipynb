{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyeX/uWrc2uV9oEqDFnxal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swapnilxi/A-computer-vision/blob/main/CNN_U2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kt8d95Z90ZT2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ojIjQ_zFvjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define CNN Architecture\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the class as a subclass of nn.Module\n",
        "        # First convolutional layera\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 input channels, 6 output channels, 5x5 kernel\n",
        "\n",
        "        # First max pooling layer\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # 2x2 kernel, stride of 2\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # 6 input channels, 16 output channels, 5x5 kernel\n",
        "\n",
        "        # Second max pooling layer\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 2x2 kernel, stride of 2\n",
        "\n",
        "        # 3 Fully connected layers\n",
        "        # Linear transformation to 120-dimensional space\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Flattening the input, 16*5*5 input features, 120 output features\n",
        "\n",
        "        # Linear transformation to 84-dimensional space\n",
        "        self.fc2 = nn.Linear(120, 84)  # 120 input features, 84 output features\n",
        "\n",
        "        # Linear transformation to 10-dimensional space (output classes)\n",
        "        self.fc3 = nn.Linear(84, 10)  # 84 input features, 10 output features (number of classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Operation 1: First convolutional layer with ReLU activation and max pooling\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Operation 2: Second convolutional layer with ReLU activation and max pooling\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Operation 3: Flattened Layer: Reshape for fully connected layer\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Operation 4: First fully connected layer with ReLU activation\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Operation 5: Second fully connected layer with ReLU activation\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Operation 6: Output layer (fully connected) with raw scores for each class\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Oep7DUGV0_nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e_8xE4S8Cqg",
        "outputId": "54d95d0c-0bdd-498a-eb2a-b6b0e4fbd214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))  # Input shape: (channels, height, width)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0w0Jc61B1M0",
        "outputId": "8f1f162b-a433-4cf8-8c07-3fe560e7e211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             456\n",
            "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
            "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
            "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
            "            Linear-5                  [-1, 120]          48,120\n",
            "            Linear-6                   [-1, 84]          10,164\n",
            "            Linear-7                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Incorporating CIFR Dataset"
      ],
      "metadata": {
        "id": "5KXYVeFeI1Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the data transform for Data Augmentation\n",
        "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomRotation(10),\n",
        "                                transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(1.0,1.0)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "piXwQ5llCGCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "#Training data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True, num_workers=2)\n",
        "\n",
        "#Test Data\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "#CIFAR-10 CLASSES\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DStoZlSCNo-",
        "outputId": "42e89ba4-5486-4e75-8774-5e3a20270191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the lengths of the trainset and testset\n",
        "print(\"Trainset length:\", len(trainset))\n",
        "print(\"Testset length:\", len(testset))"
      ],
      "metadata": {
        "id": "IQmr1XvGKnEk",
        "outputId": "910e77ca-0f9a-4581-8fc6-34230a2809d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainset length: 50000\n",
            "Testset length: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep CNN From Scratch\n"
      ],
      "metadata": {
        "id": "L97d85guuNq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define CNN Architecture\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Initialize the class as a subclass of nn.Module\n",
        "        # First convolutional layera\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 input channels, 6 output channels, 5x5 kernel\n",
        "\n",
        "        # First max pooling layer\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)  # 2x2 kernel, stride of 2\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  # 6 input channels, 16 output channels, 5x5 kernel\n",
        "\n",
        "        # Second max pooling layer\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 2x2 kernel, stride of 2\n",
        "\n",
        "        # 3 Fully connected layers\n",
        "        # Linear transformation to 120-dimensional space\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Flattening the input, 16*5*5 input features, 120 output features\n",
        "\n",
        "        # Linear transformation to 84-dimensional space\n",
        "        self.fc2 = nn.Linear(120, 84)  # 120 input features, 84 output features\n",
        "\n",
        "        # Linear transformation to 10-dimensional space (output classes)\n",
        "        self.fc3 = nn.Linear(84, 10)  # 84 input features, 10 output features (number of classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Operation 1: First convolutional layer with ReLU activation and max pooling\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Operation 2: Second convolutional layer with ReLU activation and max pooling\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Operation 3: Flattened Layer: Reshape for fully connected layer\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Operation 4: First fully connected layer with ReLU activation\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Operation 5: Second fully connected layer with ReLU activation\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Operation 6: Output layer (fully connected) with raw scores for each class\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "9mTv36vsuTIR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define DEEP CNN Architecture\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepCNN, self).__init__()\n",
        "\n",
        "        # Original Convolutional Layers\n",
        "        self.conv1_in_channels = 3\n",
        "        self.conv1_out_channels = 8\n",
        "        self.conv1_kernel_size = 3\n",
        "        self.conv1 = nn.Conv2d(self.conv1_in_channels, self.conv1_out_channels, kernel_size=self.conv1_kernel_size)\n",
        "\n",
        "\n",
        "        self.conv2_in_channels = self.conv1_out_channels\n",
        "        self.conv2_out_channels = 16\n",
        "        self.conv2_kernel_size = 2\n",
        "        self.conv2 = nn.Conv2d(self.conv2_in_channels, self.conv2_out_channels, kernel_size=self.conv2_kernel_size)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # 2 Additional Convolutional Layers\n",
        "        self.conv3_in_channels = self.conv2_out_channels\n",
        "        self.conv3_out_channels = 32\n",
        "        self.conv3_kernel_size = 2\n",
        "        self.conv3 = nn.Conv2d(self.conv3_in_channels, self.conv3_out_channels, kernel_size=self.conv3_kernel_size)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4_in_channels = self.conv3_out_channels\n",
        "        self.conv4_out_channels = 64\n",
        "        self.conv4_kernel_size = 1\n",
        "        self.conv4 = nn.Conv2d(self.conv4_in_channels, self.conv4_out_channels, kernel_size=self.conv4_kernel_size)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1_in_features = self.conv4_out_channels * 6 * 6\n",
        "        self.fc1_out_features = 100\n",
        "        self.fc1 = nn.Linear(self.fc1_in_features, self.fc1_out_features)\n",
        "\n",
        "        self.fc2_in_features = self.fc1_out_features\n",
        "        self.fc2_out_features = 10\n",
        "        self.fc2 = nn.Linear(self.fc2_in_features, self.fc2_out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Original Operations\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Additional Convolutional Layer Operation\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Faltten layer: Reshape for Fully Connected Layer\n",
        "        x = x.view(-1, self.fc1_in_features)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ccYmtI1j5VSi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepCNN()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWAeYHYn5vVd",
        "outputId": "06c69dae-d5fa-4e07-b877-004669b74469"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepCNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=2304, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using the gpu"
      ],
      "metadata": {
        "id": "bgJV8Lvt6H-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fOpSRymc6Hhj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 32, 32))  # Input shape: (channels, height, width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsS3t8e350VT",
        "outputId": "c0709aa6-569c-4184-b504-5895ff516bc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 30, 30]             224\n",
            "            Conv2d-2           [-1, 16, 29, 29]             528\n",
            "         MaxPool2d-3           [-1, 16, 14, 14]               0\n",
            "            Conv2d-4           [-1, 32, 13, 13]           2,080\n",
            "         MaxPool2d-5             [-1, 32, 6, 6]               0\n",
            "            Conv2d-6             [-1, 64, 6, 6]           2,112\n",
            "            Linear-7                  [-1, 100]         230,500\n",
            "            Linear-8                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 236,454\n",
            "Trainable params: 236,454\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.25\n",
            "Params size (MB): 0.90\n",
            "Estimated Total Size (MB): 1.16\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data loding and transform from torchvision"
      ],
      "metadata": {
        "id": "ugl28eglE1Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define the data transform for Data Augmentation\n",
        "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomRotation(10),\n",
        "                                transforms.RandomResizedCrop(32, scale=(0.8, 1.0), ratio=(1.0,1.0)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "metadata": {
        "id": "Atj-T2AiEwd8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "#Training data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "#Test Data\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "#CIFAR-10 CLASSES\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoPLntyIFL_4",
        "outputId": "dd5dcfa6-f7b6-4200-f8ce-eae1c1b88092"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the lengths of the trainset and testset\n",
        "print(\"Trainset length:\", len(trainset))\n",
        "print(\"Testset length:\", len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQv8hbhOF61o",
        "outputId": "785af5c6-a318-449d-a89a-a083d03a252a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainset length: 50000\n",
            "Testset length: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset.data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ_7pdCIFare",
        "outputId": "d700eb92-e04d-416c-8106-a1cdb7d0bdbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59,  62,  63],\n",
              "         [ 43,  46,  45],\n",
              "         [ 50,  48,  43],\n",
              "         ...,\n",
              "         [158, 132, 108],\n",
              "         [152, 125, 102],\n",
              "         [148, 124, 103]],\n",
              "\n",
              "        [[ 16,  20,  20],\n",
              "         [  0,   0,   0],\n",
              "         [ 18,   8,   0],\n",
              "         ...,\n",
              "         [123,  88,  55],\n",
              "         [119,  83,  50],\n",
              "         [122,  87,  57]],\n",
              "\n",
              "        [[ 25,  24,  21],\n",
              "         [ 16,   7,   0],\n",
              "         [ 49,  27,   8],\n",
              "         ...,\n",
              "         [118,  84,  50],\n",
              "         [120,  84,  50],\n",
              "         [109,  73,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 170,  96],\n",
              "         [201, 153,  34],\n",
              "         [198, 161,  26],\n",
              "         ...,\n",
              "         [160, 133,  70],\n",
              "         [ 56,  31,   7],\n",
              "         [ 53,  34,  20]],\n",
              "\n",
              "        [[180, 139,  96],\n",
              "         [173, 123,  42],\n",
              "         [186, 144,  30],\n",
              "         ...,\n",
              "         [184, 148,  94],\n",
              "         [ 97,  62,  34],\n",
              "         [ 83,  53,  34]],\n",
              "\n",
              "        [[177, 144, 116],\n",
              "         [168, 129,  94],\n",
              "         [179, 142,  87],\n",
              "         ...,\n",
              "         [216, 184, 140],\n",
              "         [151, 118,  84],\n",
              "         [123,  92,  72]]],\n",
              "\n",
              "\n",
              "       [[[154, 177, 187],\n",
              "         [126, 137, 136],\n",
              "         [105, 104,  95],\n",
              "         ...,\n",
              "         [ 91,  95,  71],\n",
              "         [ 87,  90,  71],\n",
              "         [ 79,  81,  70]],\n",
              "\n",
              "        [[140, 160, 169],\n",
              "         [145, 153, 154],\n",
              "         [125, 125, 118],\n",
              "         ...,\n",
              "         [ 96,  99,  78],\n",
              "         [ 77,  80,  62],\n",
              "         [ 71,  73,  61]],\n",
              "\n",
              "        [[140, 155, 164],\n",
              "         [139, 146, 149],\n",
              "         [115, 115, 112],\n",
              "         ...,\n",
              "         [ 79,  82,  64],\n",
              "         [ 68,  70,  55],\n",
              "         [ 67,  69,  55]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175, 167, 166],\n",
              "         [156, 154, 160],\n",
              "         [154, 160, 170],\n",
              "         ...,\n",
              "         [ 42,  34,  36],\n",
              "         [ 61,  53,  57],\n",
              "         [ 93,  83,  91]],\n",
              "\n",
              "        [[165, 154, 128],\n",
              "         [156, 152, 130],\n",
              "         [159, 161, 142],\n",
              "         ...,\n",
              "         [103,  93,  96],\n",
              "         [123, 114, 120],\n",
              "         [131, 121, 131]],\n",
              "\n",
              "        [[163, 148, 120],\n",
              "         [158, 148, 122],\n",
              "         [163, 156, 133],\n",
              "         ...,\n",
              "         [143, 133, 139],\n",
              "         [143, 134, 142],\n",
              "         [143, 133, 144]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113, 120, 112],\n",
              "         [111, 118, 111],\n",
              "         [105, 112, 106],\n",
              "         ...,\n",
              "         [ 72,  81,  80],\n",
              "         [ 72,  80,  79],\n",
              "         [ 72,  80,  79]],\n",
              "\n",
              "        [[111, 118, 110],\n",
              "         [104, 111, 104],\n",
              "         [ 99, 106,  98],\n",
              "         ...,\n",
              "         [ 68,  75,  73],\n",
              "         [ 70,  76,  75],\n",
              "         [ 78,  84,  82]],\n",
              "\n",
              "        [[106, 113, 105],\n",
              "         [ 99, 106,  98],\n",
              "         [ 95, 102,  94],\n",
              "         ...,\n",
              "         [ 78,  85,  83],\n",
              "         [ 79,  85,  83],\n",
              "         [ 80,  86,  84]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing loss function and optimizer"
      ],
      "metadata": {
        "id": "yS9niCrGGKtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the  optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "J8F97UuOF-xW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Data"
      ],
      "metadata": {
        "id": "ewxbHMnkGQIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(30):\n",
        "    train_loss = 0  # Initialize training loss accumulator for the epoch\n",
        "    train_acc = 0   # Initialize training accuracy accumulator for the epoch\n",
        "\n",
        "    model.train()   # Set the model to training mode\n",
        "\n",
        "    # Iterate over the training data loader\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs=inputs.to(device)\n",
        "        labels=labels.to(device)\n",
        "        optimizer.zero_grad()   # Clear previously calculated gradients\n",
        "\n",
        "        outputs = model(inputs)   # Forward pass: compute model predictions\n",
        "        loss = criterion(outputs, labels)   # Compute the loss between model predictions and ground truth labels\n",
        "        loss.backward()   # Backward pass: compute gradients of loss w.r.t. model parameters\n",
        "        optimizer.step()   # Update model parameters using the optimizer\n",
        "\n",
        "        train_loss += loss.item()   # Accumulate the training loss for the current batch\n",
        "\n",
        "        # Calculate the training accuracy for the current batch\n",
        "        _, preds = torch.max(outputs, 1)   # Get the predicted class labels\n",
        "        train_acc += (preds == labels).float().mean()   # Compute accuracy by comparing predictions with true labels\n",
        "\n",
        "    train_loss /= i + 1   # Calculate average training loss for the epoch\n",
        "    train_acc /= i + 1   # Calculate average training accuracy for the epoch\n",
        "\n",
        "    scheduler.step()   # Update the learning rate scheduler\n",
        "\n",
        "    # Print epoch-wise training loss and accuracy\n",
        "    print('Epoch {}: Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch + 1, train_loss, train_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x-pLIezGP1b",
        "outputId": "07b5f6c8-17fc-49b9-f5e0-a5b8106f3515"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 1.6250, Train Acc: 0.4062\n",
            "Epoch 2: Train Loss: 1.3696, Train Acc: 0.5067\n",
            "Epoch 3: Train Loss: 1.2549, Train Acc: 0.5528\n",
            "Epoch 4: Train Loss: 1.1758, Train Acc: 0.5805\n",
            "Epoch 5: Train Loss: 1.1151, Train Acc: 0.6063\n",
            "Epoch 6: Train Loss: 1.0666, Train Acc: 0.6231\n",
            "Epoch 7: Train Loss: 1.0329, Train Acc: 0.6385\n",
            "Epoch 8: Train Loss: 0.9436, Train Acc: 0.6694\n",
            "Epoch 9: Train Loss: 0.9252, Train Acc: 0.6737\n",
            "Epoch 10: Train Loss: 0.9162, Train Acc: 0.6796\n",
            "Epoch 11: Train Loss: 0.9150, Train Acc: 0.6815\n",
            "Epoch 12: Train Loss: 0.9063, Train Acc: 0.6844\n",
            "Epoch 13: Train Loss: 0.9023, Train Acc: 0.6851\n",
            "Epoch 14: Train Loss: 0.8981, Train Acc: 0.6851\n",
            "Epoch 15: Train Loss: 0.8842, Train Acc: 0.6922\n",
            "Epoch 16: Train Loss: 0.8828, Train Acc: 0.6916\n",
            "Epoch 17: Train Loss: 0.8816, Train Acc: 0.6930\n",
            "Epoch 18: Train Loss: 0.8784, Train Acc: 0.6941\n",
            "Epoch 19: Train Loss: 0.8793, Train Acc: 0.6925\n",
            "Epoch 20: Train Loss: 0.8799, Train Acc: 0.6927\n",
            "Epoch 21: Train Loss: 0.8816, Train Acc: 0.6916\n",
            "Epoch 22: Train Loss: 0.8774, Train Acc: 0.6921\n",
            "Epoch 23: Train Loss: 0.8800, Train Acc: 0.6943\n",
            "Epoch 24: Train Loss: 0.8768, Train Acc: 0.6932\n",
            "Epoch 25: Train Loss: 0.8769, Train Acc: 0.6950\n",
            "Epoch 26: Train Loss: 0.8793, Train Acc: 0.6924\n",
            "Epoch 27: Train Loss: 0.8772, Train Acc: 0.6921\n",
            "Epoch 28: Train Loss: 0.8783, Train Acc: 0.6954\n",
            "Epoch 29: Train Loss: 0.8779, Train Acc: 0.6927\n",
            "Epoch 30: Train Loss: 0.8780, Train Acc: 0.6928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing and evaluating"
      ],
      "metadata": {
        "id": "O3qDqYxMGwNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model on the Test Set\n",
        "with torch.no_grad():   # Context manager to disable gradient calculation\n",
        "    correct = 0   # Initialize variable to count correct predictions\n",
        "    total = 0   # Initialize variable to count total number of samples\n",
        "    for images, labels in testloader:   # Iterate over the test loader\n",
        "        images=images.to(device)\n",
        "        labels=labels.to(device)\n",
        "        outputs = model(images)   # Forward pass: compute model predictions\n",
        "        _, predicted = torch.max(outputs.data, 1)   # Get the index of the class with the highest probability\n",
        "        total += labels.size(0)   # Increment the total count by the batch size\n",
        "        correct += (predicted == labels).sum().item()   # Count the number of correct predictions in the batch\n",
        "\n",
        "    # Print the accuracy of the model on the Test Images\n",
        "    print(f'Accuracy of the network on the validation images: {100 * correct / total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KslUv87JGAsY",
        "outputId": "d20bc8c3-e032-42d8-8fe3-c2abca6d4d2a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the validation images: 67.51 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X5d-1ocJFad8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6hKq6acCFZ2c"
      }
    }
  ]
}